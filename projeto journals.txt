NOME_DO_CANDIDATO = 'Flavio de Souza dos Anjos Bitureira'
EMAIL_DO_CANDIDATO = 'flaviosouzaanjos21@gmail.com'

import json
import datetime
import calendar
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path
from time import sleep
from typing import Dict, List, Tuple

import requests

MAIN_FOLDER = Path(__file__).parent.parent


def request_journals(start_date, end_date):
    url = 'https://engine.procedebahia.com.br/publish/api/diaries'
    r = requests.post(url, data={"cod_entity": '50', "start_date": start_date,
                                 "end_date": end_date})
    if r.status_code == 200:
        return r.json()
    elif r.status_code == 400:
        sleep(10)
        return request_journals(start_date, end_date)
    return {print ('Erro')}


def download_jornal(edition, path):
    url = 'http://procedebahia.com.br/irece/publicacoes/Diario%20Oficial' \
          '%20-%20PREFEITURA%20MUNICIPAL%20DE%20IRECE%20-%20Ed%20{:04d}.pdf'.format(int(edition))
    r = requests.get(url, allow_redirects=True)
    if r.status_code == 200:
        with open(path, 'wb') as writer:
            writer.write(r.content)
        return edition, path
    return edition, ''


def download_mutiple_jornals(editions, paths):
    threads = []
    with ThreadPoolExecutor(max_workers=10) as executor:
        for edition, path in zip(editions, paths):            
            threads.append(executor.submit(download_jornal, edition, path))

        results = []
        for task in as_completed(threads):
            results.append(task.result())

    results = [[r for r in results if r[0] == e][0] for e in editions]
    return [r[1] for r in results]


class JournalDownloader:
    def _init_(self):
        self.pdfs_folder = MAIN_FOLDER / 'pdfs'
        self.jsons_folder = MAIN_FOLDER / 'out'

        self.pdfs_folder.mkdir(exist_ok=True)
        self.jsons_folder.mkdir(exist_ok=True)
        
    def get_day_journals(self, year: int, month: int, day: int) -> List[str]:
        assert year >= 1970 ,"Ano deve ser maior que 1969"
        isDataValida = True
        try:
            datetime.datetime(int(year), int(month), int(day))
        except ValueError:
            isDataValida = False
        assert isDataValida ,'Data invalida'
        
        
        
        journals = request_journals(str(year)+"-"+str(month)+"-"+str(day),str(year)+"-"+str(month)+"-"+str(day))
        diaries = journals["diaries"]
        for journal in diaries:
            print(self.dump_json(journal["arquivo"],journal["edicao"],journal["data"]))
        pass

    def get_month_journals(self, year: int, month: int) -> List[str]:
        assert year >= 1970,"Ano deve ser maior ou igual a 1970"
        assert month < 13, "Ano deve ser menor ou igual a 12"
        assert month > 1, "Ano deve ser maior ou igual a 1"
        
        primeiroDia = calendar.monthrange(year, month)[0]
        ultimoDia = calendar.monthrange(year, month)[1]
        
        journals = request_journals(str(year)+"-"+str(month)+"-"+str(primeiroDia),str(year)+"-"+str(month)+"-"+str(ultimoDia))
        diaries = journals["diaries"]
        for journal in diaries:
            print(self.dump_json(journal["arquivo"],journal["edicao"],journal["data"]))
        pass

    def get_year_journals(self, year: int) -> List[str]:
        assert year >= 1970,"Ano deve ser maior ou igual a 1970"
        
        journals = request_journals(str(year)+'-01-01',str(year)+'-12-31')
        diaries = journals["diaries"]
        for journal in diaries:
            print(self.dump_json(journal["arquivo"],journal["edicao"],journal["data"]))
        pass

    @staticmethod
    def parse(response: Dict) -> List[Tuple[str, str]]:
        lista = list()
        for resp in response:
            lista.append(Tuple["data","edicao"])
        return lista
        

    def download_all(self, editions: List[str]) -> List[str]:
        pdfPaths = []
        editions.sort()
        i = 0
        for edition in editions:
            pdfPaths.append(str(self.pdfs_folder)+"\\"+str(i)+".pdf")
            i+=1
        download_mutiple_jornals(editions,pdfPaths)
        pass

    def dump_json(self, pdf_path: str, edition: str, date: str) -> str:
        if pdf_path == '':
            return ''
        output_path = self.jsons_folder / f"{edition}.json"
        data = {
            'path': str(pdf_path),
            'name': str(edition),
            'date': date,
            'origin': 'Irece-BA/DOM'
        }
        with open(output_path, 'w', encoding='utf-8') as file:
            file.write(json.dumps(data,
                                  indent=4, ensure_ascii=False))
        return str(output_path)


